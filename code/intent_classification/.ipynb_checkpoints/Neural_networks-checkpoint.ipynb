{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MathildeElimas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MathildeElimas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MathildeElimas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from data_processing import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.metrics import multilabel_confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, BatchNormalization, LSTM, InputLayer, Flatten\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + '\\\\data'\n",
    "method = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence           Intent\n",
      "0  Bonjour j'ai rendu mon équipement box est je n...  probleme_box_tv\n",
      "1                                            Bonjour  probleme_box_tv\n",
      "2                              Box internet en panne  probleme_box_tv\n",
      "3  Plus de phone ni internet depuis plus ou moins...  probleme_box_tv\n",
      "4  Bonjour j'ai la télécommande de ma box qui ne ...  probleme_box_tv\n"
     ]
    }
   ],
   "source": [
    "# intent, unique_intent, sentences = load_data(PATH + '\\\\training_recast2.csv', \n",
    "#                                              sep = ';', header = 1, encoding = \"cp1252\", \n",
    "#                                              names = [\"Sentence\", \"Intent\", \"Description\"], index_col= False)\n",
    "\n",
    "intent, unique_intent, sentences = load_data(PATH + '\\\\intent_dialogues.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-27 15:21:04,874 - spacy_lefff.lefff - INFO - New LefffLemmatizer instantiated.\n",
      "2020-10-27 15:21:04,875 - spacy_lefff.lefff - INFO - Reading lefff data...\n",
      "2020-10-27 15:21:05,273 - spacy_lefff.lefff - INFO - Successfully loaded lefff lemmatizer\n"
     ]
    }
   ],
   "source": [
    "idx, cleaned_words = clean_sentences(sentences)\n",
    "intent = list(map(intent.__getitem__, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-27 15:21:31,687 - numexpr.utils - INFO - NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "vocab = create_vocabulary(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_doc = text_embedding(cleaned_words, vocab = list(vocab.keys()), encoding = 'word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = len(max(cleaned_words, key = len))\n",
    "# vocab_size = encoded_doc.shape[1]\n",
    "# print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2855, 34, 300)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intent embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probleme_box_tv': 1, 'reseau_mobile': 2, 'explication_facture': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')\n",
    "output_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_encoder, encoded_output = intent_embedding(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = intent_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['explication_facture', 'probleme_box_tv', 'reseau_mobile'],\n",
       "       dtype='<U19')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(encoded_doc, encoded_output, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X = (2284, 34, 300) and train_Y = (2284, 3)\n",
      "Shape of val_X = (571, 34, 300) and val_Y = (571, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
    "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(InputLayer(input_shape = encoded_doc.shape[1:]))\n",
    "#     model.add(Embedding(vocab_size, 64))\n",
    "#    model.add(Bidirectional(LSTM(128))) \n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len(unique_intent), activation = \"softmax\")) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 34, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 34, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 34, 64)            4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 34, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2176)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 6531      \n",
      "=================================================================\n",
      "Total params: 29,955\n",
      "Trainable params: 29,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"categorical_accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2284, 34, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [np.argmax(x) for x in train_Y]\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(labels),\n",
    "                                                 labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2284/2284 [==============================] - 1s 316us/step - loss: 1.0597 - categorical_accuracy: 0.4803\n",
      "\n",
      "Epoch 00001: categorical_accuracy improved from -inf to 0.48030, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 2/50\n",
      "2284/2284 [==============================] - 1s 233us/step - loss: 0.7959 - categorical_accuracy: 0.6629\n",
      "\n",
      "Epoch 00002: categorical_accuracy improved from 0.48030 to 0.66287, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 3/50\n",
      "2284/2284 [==============================] - 1s 248us/step - loss: 0.6905 - categorical_accuracy: 0.7272\n",
      "\n",
      "Epoch 00003: categorical_accuracy improved from 0.66287 to 0.72723, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 4/50\n",
      "2284/2284 [==============================] - 0s 180us/step - loss: 0.6327 - categorical_accuracy: 0.7487\n",
      "\n",
      "Epoch 00004: categorical_accuracy improved from 0.72723 to 0.74869, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 5/50\n",
      "2284/2284 [==============================] - 0s 162us/step - loss: 0.5914 - categorical_accuracy: 0.7697\n",
      "\n",
      "Epoch 00005: categorical_accuracy improved from 0.74869 to 0.76970, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 6/50\n",
      "2284/2284 [==============================] - 0s 156us/step - loss: 0.5704 - categorical_accuracy: 0.7745\n",
      "\n",
      "Epoch 00006: categorical_accuracy improved from 0.76970 to 0.77452, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 7/50\n",
      "2284/2284 [==============================] - 0s 162us/step - loss: 0.5376 - categorical_accuracy: 0.7863\n",
      "\n",
      "Epoch 00007: categorical_accuracy improved from 0.77452 to 0.78634, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 8/50\n",
      "2284/2284 [==============================] - 0s 155us/step - loss: 0.5111 - categorical_accuracy: 0.7973\n",
      "\n",
      "Epoch 00008: categorical_accuracy improved from 0.78634 to 0.79729, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 9/50\n",
      "2284/2284 [==============================] - 0s 181us/step - loss: 0.5088 - categorical_accuracy: 0.7999\n",
      "\n",
      "Epoch 00009: categorical_accuracy improved from 0.79729 to 0.79991, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 10/50\n",
      "2284/2284 [==============================] - 0s 180us/step - loss: 0.4753 - categorical_accuracy: 0.8148\n",
      "\n",
      "Epoch 00010: categorical_accuracy improved from 0.79991 to 0.81480, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 11/50\n",
      "2284/2284 [==============================] - 0s 173us/step - loss: 0.4596 - categorical_accuracy: 0.8174\n",
      "\n",
      "Epoch 00011: categorical_accuracy improved from 0.81480 to 0.81743, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 12/50\n",
      "2284/2284 [==============================] - 0s 189us/step - loss: 0.4564 - categorical_accuracy: 0.8214\n",
      "\n",
      "Epoch 00012: categorical_accuracy improved from 0.81743 to 0.82137, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 13/50\n",
      "2284/2284 [==============================] - 0s 148us/step - loss: 0.4382 - categorical_accuracy: 0.8279\n",
      "\n",
      "Epoch 00013: categorical_accuracy improved from 0.82137 to 0.82793, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 14/50\n",
      "2284/2284 [==============================] - 0s 138us/step - loss: 0.4266 - categorical_accuracy: 0.8336\n",
      "\n",
      "Epoch 00014: categorical_accuracy improved from 0.82793 to 0.83363, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 15/50\n",
      "2284/2284 [==============================] - 0s 137us/step - loss: 0.4172 - categorical_accuracy: 0.8402\n",
      "\n",
      "Epoch 00015: categorical_accuracy improved from 0.83363 to 0.84019, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 16/50\n",
      "2284/2284 [==============================] - 0s 137us/step - loss: 0.4058 - categorical_accuracy: 0.8450\n",
      "\n",
      "Epoch 00016: categorical_accuracy improved from 0.84019 to 0.84501, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 17/50\n",
      "2284/2284 [==============================] - 0s 150us/step - loss: 0.4081 - categorical_accuracy: 0.8398\n",
      "\n",
      "Epoch 00017: categorical_accuracy did not improve from 0.84501\n",
      "Epoch 18/50\n",
      "2284/2284 [==============================] - 0s 165us/step - loss: 0.3870 - categorical_accuracy: 0.8529\n",
      "\n",
      "Epoch 00018: categorical_accuracy improved from 0.84501 to 0.85289, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 19/50\n",
      "2284/2284 [==============================] - 0s 168us/step - loss: 0.3874 - categorical_accuracy: 0.8472\n",
      "\n",
      "Epoch 00019: categorical_accuracy did not improve from 0.85289\n",
      "Epoch 20/50\n",
      "2284/2284 [==============================] - 0s 147us/step - loss: 0.3824 - categorical_accuracy: 0.8511\n",
      "\n",
      "Epoch 00020: categorical_accuracy did not improve from 0.85289\n",
      "Epoch 21/50\n",
      "2284/2284 [==============================] - 0s 159us/step - loss: 0.3620 - categorical_accuracy: 0.8533\n",
      "\n",
      "Epoch 00021: categorical_accuracy improved from 0.85289 to 0.85333, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 22/50\n",
      "2284/2284 [==============================] - 0s 154us/step - loss: 0.3696 - categorical_accuracy: 0.8573\n",
      "\n",
      "Epoch 00022: categorical_accuracy improved from 0.85333 to 0.85727, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 23/50\n",
      "2284/2284 [==============================] - 0s 147us/step - loss: 0.3592 - categorical_accuracy: 0.8511\n",
      "\n",
      "Epoch 00023: categorical_accuracy did not improve from 0.85727\n",
      "Epoch 24/50\n",
      "2284/2284 [==============================] - 0s 140us/step - loss: 0.3493 - categorical_accuracy: 0.8634\n",
      "\n",
      "Epoch 00024: categorical_accuracy improved from 0.85727 to 0.86340, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 25/50\n",
      "2284/2284 [==============================] - 0s 156us/step - loss: 0.3432 - categorical_accuracy: 0.8665\n",
      "\n",
      "Epoch 00025: categorical_accuracy improved from 0.86340 to 0.86646, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 26/50\n",
      "2284/2284 [==============================] - 0s 139us/step - loss: 0.3235 - categorical_accuracy: 0.8752\n",
      "\n",
      "Epoch 00026: categorical_accuracy improved from 0.86646 to 0.87522, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 27/50\n",
      "2284/2284 [==============================] - 0s 137us/step - loss: 0.3246 - categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00027: categorical_accuracy did not improve from 0.87522\n",
      "Epoch 28/50\n",
      "2284/2284 [==============================] - 0s 143us/step - loss: 0.3397 - categorical_accuracy: 0.8704\n",
      "\n",
      "Epoch 00028: categorical_accuracy did not improve from 0.87522\n",
      "Epoch 29/50\n",
      "2284/2284 [==============================] - 0s 140us/step - loss: 0.3130 - categorical_accuracy: 0.8800\n",
      "\n",
      "Epoch 00029: categorical_accuracy improved from 0.87522 to 0.88004, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 30/50\n",
      "2284/2284 [==============================] - 0s 155us/step - loss: 0.3097 - categorical_accuracy: 0.8787\n",
      "\n",
      "Epoch 00030: categorical_accuracy did not improve from 0.88004\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2284/2284 [==============================] - 0s 141us/step - loss: 0.3200 - categorical_accuracy: 0.8840\n",
      "\n",
      "Epoch 00031: categorical_accuracy improved from 0.88004 to 0.88398, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 32/50\n",
      "2284/2284 [==============================] - 0s 140us/step - loss: 0.3204 - categorical_accuracy: 0.8792\n",
      "\n",
      "Epoch 00032: categorical_accuracy did not improve from 0.88398\n",
      "Epoch 33/50\n",
      "2284/2284 [==============================] - 0s 139us/step - loss: 0.3050 - categorical_accuracy: 0.8835\n",
      "\n",
      "Epoch 00033: categorical_accuracy did not improve from 0.88398\n",
      "Epoch 34/50\n",
      "2284/2284 [==============================] - 0s 136us/step - loss: 0.3070 - categorical_accuracy: 0.8857\n",
      "\n",
      "Epoch 00034: categorical_accuracy improved from 0.88398 to 0.88573, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 35/50\n",
      "2284/2284 [==============================] - 0s 138us/step - loss: 0.2894 - categorical_accuracy: 0.8932\n",
      "\n",
      "Epoch 00035: categorical_accuracy improved from 0.88573 to 0.89317, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 36/50\n",
      "2284/2284 [==============================] - 0s 149us/step - loss: 0.2837 - categorical_accuracy: 0.8914\n",
      "\n",
      "Epoch 00036: categorical_accuracy did not improve from 0.89317\n",
      "Epoch 37/50\n",
      "2284/2284 [==============================] - 0s 136us/step - loss: 0.2843 - categorical_accuracy: 0.8901\n",
      "\n",
      "Epoch 00037: categorical_accuracy did not improve from 0.89317\n",
      "Epoch 38/50\n",
      "2284/2284 [==============================] - 0s 135us/step - loss: 0.3054 - categorical_accuracy: 0.8849\n",
      "\n",
      "Epoch 00038: categorical_accuracy did not improve from 0.89317\n",
      "Epoch 39/50\n",
      "2284/2284 [==============================] - 0s 135us/step - loss: 0.2765 - categorical_accuracy: 0.8919\n",
      "\n",
      "Epoch 00039: categorical_accuracy did not improve from 0.89317\n",
      "Epoch 40/50\n",
      "2284/2284 [==============================] - 0s 134us/step - loss: 0.2788 - categorical_accuracy: 0.8967\n",
      "\n",
      "Epoch 00040: categorical_accuracy improved from 0.89317 to 0.89667, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 41/50\n",
      "2284/2284 [==============================] - 0s 154us/step - loss: 0.2772 - categorical_accuracy: 0.8905\n",
      "\n",
      "Epoch 00041: categorical_accuracy did not improve from 0.89667\n",
      "Epoch 42/50\n",
      "2284/2284 [==============================] - 0s 138us/step - loss: 0.2704 - categorical_accuracy: 0.8984\n",
      "\n",
      "Epoch 00042: categorical_accuracy improved from 0.89667 to 0.89842, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 43/50\n",
      "2284/2284 [==============================] - 0s 136us/step - loss: 0.2805 - categorical_accuracy: 0.8984\n",
      "\n",
      "Epoch 00043: categorical_accuracy did not improve from 0.89842\n",
      "Epoch 44/50\n",
      "2284/2284 [==============================] - 0s 145us/step - loss: 0.2629 - categorical_accuracy: 0.9024\n",
      "\n",
      "Epoch 00044: categorical_accuracy improved from 0.89842 to 0.90236, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 45/50\n",
      "2284/2284 [==============================] - 0s 161us/step - loss: 0.2741 - categorical_accuracy: 0.8975\n",
      "\n",
      "Epoch 00045: categorical_accuracy did not improve from 0.90236\n",
      "Epoch 46/50\n",
      "2284/2284 [==============================] - 0s 159us/step - loss: 0.2701 - categorical_accuracy: 0.8997\n",
      "\n",
      "Epoch 00046: categorical_accuracy did not improve from 0.90236\n",
      "Epoch 47/50\n",
      "2284/2284 [==============================] - 0s 142us/step - loss: 0.2649 - categorical_accuracy: 0.9011\n",
      "\n",
      "Epoch 00047: categorical_accuracy did not improve from 0.90236\n",
      "Epoch 48/50\n",
      "2284/2284 [==============================] - 0s 147us/step - loss: 0.2534 - categorical_accuracy: 0.9046\n",
      "\n",
      "Epoch 00048: categorical_accuracy improved from 0.90236 to 0.90455, saving model to C:\\Users\\MathildeElimas\\OneDrive - Datatorii\\Documents\\BYTEL\\code\\intent_classification/model.h5\n",
      "Epoch 49/50\n",
      "2284/2284 [==============================] - 0s 157us/step - loss: 0.2693 - categorical_accuracy: 0.8923\n",
      "\n",
      "Epoch 00049: categorical_accuracy did not improve from 0.90455\n",
      "Epoch 50/50\n",
      "2284/2284 [==============================] - 0s 173us/step - loss: 0.2673 - categorical_accuracy: 0.8940\n",
      "\n",
      "Epoch 00050: categorical_accuracy did not improve from 0.90455\n"
     ]
    }
   ],
   "source": [
    "filename = os.getcwd() + '/model.h5'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='categorical_accuracy', \n",
    "                             verbose=1, save_best_only=True, \n",
    "                             mode='max')\n",
    "\n",
    "hist = model.fit(train_X, train_Y, #class_weight = class_weights,\n",
    "                 epochs = 50, batch_size = 32, \n",
    "                 callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6491697731253284"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba = model.predict(val_X)\n",
    "pred_class = [np.argmax(x) for x in pred_proba]\n",
    "val_Y_class = [np.argmax(x) for x in val_Y]\n",
    "balanced_accuracy_score(val_Y_class, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_conf_mat(true, pred_proba, seuil):\n",
    "    pred = [[np.argmax(x), max(x)] for x in pred_proba]\n",
    "    VP, FP, VN, FN = 0, 0, 0, 0\n",
    "    for i in range(len(true)):\n",
    "        if pred[i][1] >= seuil:\n",
    "            if pred[i][0] == true[i]:\n",
    "                VP += 1\n",
    "            else :\n",
    "                FP += 1\n",
    "        else : \n",
    "            if pred[i][0] == true[i]:\n",
    "                VN += 1\n",
    "            else :\n",
    "                FN += 1 \n",
    "    return np.array([[VP,FP],[VN,FN]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-369a8d2f0e59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmulticlass_conf_mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.33\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-60c62b29b65f>\u001b[0m in \u001b[0;36mmulticlass_conf_mat\u001b[1;34m(true, pred_proba, seuil)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mseuil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                 \u001b[0mVP\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "multiclass_conf_mat(val_Y, pred_proba, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text, vocab = vocab, encoding = 'count'):\n",
    "    clean = clean_sentences(text)\n",
    "    _, test_ls = text_embedding(clean, vocab, encoding)\n",
    "    \n",
    "    #Check for unknown words\n",
    "    if [] in test_ls:\n",
    "        test_ls = list(filter(None, test_ls))\n",
    "\n",
    "#     test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
    "\n",
    "    pred = model.predict_proba(test_ls)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Je ne comprends pas ma dernière facture. Il y a une augmentation de 2euros.\"\n",
    "pred_text = predictions([text])\n",
    "intent_encoder.inverse_transform(pred_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
